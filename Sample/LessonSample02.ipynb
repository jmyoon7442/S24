{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmyoon7442/S24/blob/main/Sample/LessonSample02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ± **Lesson Sample 02**\n",
        "\n",
        "+ What is sound?\n",
        "+ Dialectal vowel variation\n",
        "+ Listening and speaking"
      ],
      "metadata": {
        "id": "2gkekYy0RI1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gTTS\n",
        "from gtts import gTTS\n",
        "from IPython.display import YouTubeVideo, display, Audio, Image\n",
        "#@markdown ðŸ”„ Install {pydub} {gtts}\n",
        "%%capture\n",
        "!pip install pydub"
      ],
      "metadata": {
        "id": "h_mrClnPK0kl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mydkqYLxHh3C",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ðŸ”„ Making functions: etts('text'), ktts('text')\n",
        "\n",
        "\n",
        "def etts(text):\n",
        "  text_to_say = text\n",
        "\n",
        "  gtts_object = gTTS(text = text_to_say,\n",
        "                     lang = \"en\", tld = \"us\",\n",
        "                    slow = False)\n",
        "\n",
        "  gtts_object.save(\"E-audio.mp3\")\n",
        "  return Audio(\"E-audio.mp3\")\n",
        "\n",
        "def ktts(text):\n",
        "  text_to_say = text\n",
        "\n",
        "  gtts_object = gTTS(text = text_to_say,\n",
        "                     lang = \"ko\",\n",
        "                    slow = False)\n",
        "\n",
        "  gtts_object.save(\"K-audio.mp3\")\n",
        "  return Audio(\"K-audio.mp3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[1] What is sound?**\n",
        "\n",
        "+ Sound to the brain\n",
        "+ Pysical aspect (acoustics)\n",
        "+ Pysiological aspect"
      ],
      "metadata": {
        "id": "B0crfy-7eoVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Travel of sound to the brain"
      ],
      "metadata": {
        "id": "l_u5HA6x_JhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ðŸŽ¬ Journey of sound to the brain 2m 26s\n",
        "from IPython.display import YouTubeVideo, display\n",
        "video = YouTubeVideo(\"eQEaiZ2j9oc\", width=600, height=\"400\")\n",
        "display(video)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xREMHkyc_JhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Generating sound (digital signal)"
      ],
      "metadata": {
        "id": "832pbg-5hS0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ðŸ”„ (2/4)Generate a sample speech (File: E-audio.mp3):\n",
        "\n",
        "txt = input(\"Type text: \")\n",
        "etts(txt)\n",
        "Audio(\"E-audio.mp3\", autoplay=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "G8w6sROqfFgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ðŸ”„ (3/4) Specify file names to convert: ðŸ“Œ E-audio.mp3 => save as \"sample.wav\"\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "inaudio = \"E-audio.mp3\"\n",
        "outaudio = \"sample.wav\"\n",
        "sound = AudioSegment.from_mp3(inaudio)\n",
        "sound.export(outaudio, format=\"wav\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T3vCaf4SfWvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ðŸ”„ (4/4) Display waveform:\n",
        "import scipy.io.wavfile as wavfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pydub import AudioSegment  # Make sure to import AudioSegment\n",
        "\n",
        "# Assuming 'outaudio' is defined and points to your audio file\n",
        "audio = AudioSegment.from_file(outaudio, format=\"wav\")\n",
        "print(\"Sampling rate: \", audio.frame_rate)\n",
        "# Assuming 'txt' is defined and holds some text\n",
        "print(f\"Text: {txt}\")\n",
        "\n",
        "fs, data = wavfile.read(outaudio)  # Replace 'outaudio' with the name of your audio file\n",
        "duration = len(data) / fs  # Calculate the duration of your audio file in seconds\n",
        "\n",
        "# Create a time array in seconds\n",
        "time = np.linspace(0., duration, len(data))\n",
        "\n",
        "plt.figure(figsize=(18,4))\n",
        "plt.xlabel('time (seconds)')  # Update the label to show time in seconds\n",
        "plt.plot(time, data)  # Plot the data against time in seconds\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "r3YlQr2s-GQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ðŸ”„ Zoom in the waveform (start, end)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "import numpy as np  # Ensure numpy is imported\n",
        "\n",
        "# Read the waveform data\n",
        "rate, data = wavfile.read('/content/sample.wav')\n",
        "\n",
        "# Calculate the duration of your audio file in seconds\n",
        "duration = len(data) / rate\n",
        "\n",
        "# Create a time array in seconds\n",
        "time = np.linspace(0., duration, len(data))\n",
        "\n",
        "# Plot the waveform\n",
        "fig, ax = plt.subplots(figsize=(18, 3))\n",
        "\n",
        "# Plot with time array\n",
        "ax.plot(time, data)\n",
        "\n",
        "st = input(\"Start time (sec.) e.g., 0.52: \")\n",
        "et = input(\"End time (sec.) e.g., 0.8: \")\n",
        "\n",
        "# Convert input times to float\n",
        "start_time = float(st)  # start time in seconds\n",
        "end_time = float(et)  # end time in seconds\n",
        "\n",
        "# Since the x-axis is now in seconds, directly use start_time and end_time\n",
        "ax.set_xlim(start_time, end_time)\n",
        "\n",
        "plt.xlabel('Time (seconds)')  # Label the x-axis as time in seconds\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7j9bZ_0q-umF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[2] Dialectal vowel variation**\n",
        "\n",
        "+ Example: yes-no question\n",
        "```\n",
        "Would you like some coffee?\n",
        "What brought you here?\n",
        "```"
      ],
      "metadata": {
        "id": "7ucLgS0IelLf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Dc80jg0EdBXk"
      },
      "outputs": [],
      "source": [
        "#@markdown ðŸŽ§ TTS with dialectal variation. (Not so reliable.)\n",
        "\n",
        "variety = \"en-us\" #@param = [\"en-us\",\"en-co.uk\",\"en-ie\",\"en-co.in\"]\n",
        "v1 = variety.split('-')\n",
        "language = v1[0]\n",
        "dialect = v1[1]\n",
        "\n",
        "#@markdown Sample text: I'm thirty and my wife is thirty too.\n",
        "text_to_say = input(\"Type text: \")\n",
        "gtts_object = gTTS(text = text_to_say,\n",
        "                   lang = language, tld = dialect,\n",
        "                   slow = False)\n",
        "\n",
        "gtts_object.save(\"E-audio.mp3\")\n",
        "Audio(\"E-audio.mp3\", autoplay=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = input()\n",
        "ktts(txt)\n",
        "Audio(\"K-audio.mp3\", autoplay=True)"
      ],
      "metadata": {
        "id": "c6JzgD3Zh4ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’¦ [Application](https://mrkim21.github.io/appfolder/foreignaccent.html): Foreign accents"
      ],
      "metadata": {
        "id": "nHuUPUnPSt5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying an image"
      ],
      "metadata": {
        "id": "usSGmxTfToAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Critical Period Hypothesis\n",
        "from IPython.display import display, Image\n",
        "url = \"https://github.com/MK316/images/raw/main/CPH.png\"\n",
        "Image(url, width =\" 600\", height = \"500\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hZOEVDj9b_Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ˜Š Demo: Q & As (Teacher's exam)\n",
        "\n",
        "Accented speech and intelligibility"
      ],
      "metadata": {
        "id": "3Z7lwckqTy09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Question:\n",
        "\n",
        "text1 = \"Here's a question for you: What qualities are essential to effectively educate and inspire future generations?\"\n",
        "etts(text1)\n",
        "print(\"Question:\")\n",
        "display(Audio(\"E-audio.mp3\"))\n",
        "\n",
        "text2 = \"A good teacher must be technologically savvy, not just in using educational technology? but in integrating it meaningfully into lessons to enhance learning. They should prepare students to be digitally literate, critical thinkers in an online world.\"\n",
        "ktts(text2)\n",
        "print(\"Answer: with Korean accent\")\n",
        "display(Audio(\"K-audio.mp3\"))\n",
        "\n",
        "\n",
        "text2 = \"A good teacher must be technologically savvy, not just in using educational technology, but in integrating it meaningfully into lessons to enhance learning. They should prepare students to be digitally literate, critical thinkers in an online world.\"\n",
        "etts(text2)\n",
        "print(\"Answer: with American accent\")\n",
        "display(Audio(\"E-audio.mp3\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VtwDAOg8T0W1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}